{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Medical Chatbot","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T12:41:49.166588Z","iopub.execute_input":"2023-10-01T12:41:49.166850Z","iopub.status.idle":"2023-10-01T12:41:49.173022Z","shell.execute_reply.started":"2023-10-01T12:41:49.166827Z","shell.execute_reply":"2023-10-01T12:41:49.172119Z"}}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:19:31.581427Z","iopub.execute_input":"2023-10-24T03:19:31.582129Z","iopub.status.idle":"2023-10-24T03:19:32.665969Z","shell.execute_reply.started":"2023-10-24T03:19:31.582081Z","shell.execute_reply":"2023-10-24T03:19:32.664751Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Tue Oct 24 03:19:32 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers tokenizers sentencepiece torchtext pytorch_lightning numpy>=1.16.5 datasets --quiet","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:20:03.205405Z","iopub.execute_input":"2023-10-24T03:20:03.205752Z","iopub.status.idle":"2023-10-24T03:20:15.296262Z","shell.execute_reply.started":"2023-10-24T03:20:03.205720Z","shell.execute_reply":"2023-10-24T03:20:15.295016Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport pytorch_lightning as pl\n\nfrom datasets import load_dataset\n\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:20:15.298963Z","iopub.execute_input":"2023-10-24T03:20:15.299288Z","iopub.status.idle":"2023-10-24T03:20:15.309280Z","shell.execute_reply.started":"2023-10-24T03:20:15.299259Z","shell.execute_reply":"2023-10-24T03:20:15.308292Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_url = '/kaggle/input/medical-data-folder/finalPreprocessed.csv'","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:23:53.897032Z","iopub.execute_input":"2023-10-24T03:23:53.898159Z","iopub.status.idle":"2023-10-24T03:23:53.902641Z","shell.execute_reply.started":"2023-10-24T03:23:53.898114Z","shell.execute_reply":"2023-10-24T03:23:53.901469Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = 'distilbert-base-uncased'","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:20:15.310454Z","iopub.execute_input":"2023-10-24T03:20:15.310806Z","iopub.status.idle":"2023-10-24T03:20:15.320985Z","shell.execute_reply.started":"2023-10-24T03:20:15.310773Z","shell.execute_reply":"2023-10-24T03:20:15.319986Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(data_url)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:24:04.890030Z","iopub.execute_input":"2023-10-24T03:24:04.890518Z","iopub.status.idle":"2023-10-24T03:24:07.533872Z","shell.execute_reply.started":"2023-10-24T03:24:04.890485Z","shell.execute_reply":"2023-10-24T03:24:07.532808Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data[data.duplicated()]","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:25:41.409437Z","iopub.execute_input":"2023-10-24T03:25:41.409771Z","iopub.status.idle":"2023-10-24T03:25:41.742320Z","shell.execute_reply.started":"2023-10-24T03:25:41.409746Z","shell.execute_reply":"2023-10-24T03:25:41.741338Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                                                Questions  \\\n11139   Are type D personality and depressive symptoms...   \n11589   Are inflammatory markers unrelated to physical...   \n25561                    What causes Causes of Diabetes ?   \n30970   Does astragaloside IV attenuate inflammatory c...   \n31612   Does sodium Intake During an Ultramarathon Pre...   \n...                                                   ...   \n225870                   What causes Causes of Diabetes ?   \n225884  Does mOLECULAR CHARACTERISATION AND ANTIMICROB...   \n226805  Does physical activity overcome the effects of...   \n227575           What are the treatments for Acromegaly ?   \n227594               What to do for Glomerular Diseases ?   \n\n                                                  Answers  \n11139   Type D personality and depressive symptoms wer...  \n11589   Although dietary intake and inflammation may i...  \n25561   Other types of diabetes have a variety of poss...  \n30970   The results of these studies indicate that Ast...  \n31612   Exercise-associated muscle cramping, dehydrati...  \n...                                                   ...  \n225870  Type 1 diabetes is caused by a lack of insulin...  \n225884  This study demonstrated that there is a signif...  \n226805  It is recommended that programs to combat sede...  \n227575  Currently, treatment options include surgical ...  \n227594  - The kidneys filter waste and extra fluid fro...  \n\n[129 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11139</th>\n      <td>Are type D personality and depressive symptoms...</td>\n      <td>Type D personality and depressive symptoms wer...</td>\n    </tr>\n    <tr>\n      <th>11589</th>\n      <td>Are inflammatory markers unrelated to physical...</td>\n      <td>Although dietary intake and inflammation may i...</td>\n    </tr>\n    <tr>\n      <th>25561</th>\n      <td>What causes Causes of Diabetes ?</td>\n      <td>Other types of diabetes have a variety of poss...</td>\n    </tr>\n    <tr>\n      <th>30970</th>\n      <td>Does astragaloside IV attenuate inflammatory c...</td>\n      <td>The results of these studies indicate that Ast...</td>\n    </tr>\n    <tr>\n      <th>31612</th>\n      <td>Does sodium Intake During an Ultramarathon Pre...</td>\n      <td>Exercise-associated muscle cramping, dehydrati...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>225870</th>\n      <td>What causes Causes of Diabetes ?</td>\n      <td>Type 1 diabetes is caused by a lack of insulin...</td>\n    </tr>\n    <tr>\n      <th>225884</th>\n      <td>Does mOLECULAR CHARACTERISATION AND ANTIMICROB...</td>\n      <td>This study demonstrated that there is a signif...</td>\n    </tr>\n    <tr>\n      <th>226805</th>\n      <td>Does physical activity overcome the effects of...</td>\n      <td>It is recommended that programs to combat sede...</td>\n    </tr>\n    <tr>\n      <th>227575</th>\n      <td>What are the treatments for Acromegaly ?</td>\n      <td>Currently, treatment options include surgical ...</td>\n    </tr>\n    <tr>\n      <th>227594</th>\n      <td>What to do for Glomerular Diseases ?</td>\n      <td>- The kidneys filter waste and extra fluid fro...</td>\n    </tr>\n  </tbody>\n</table>\n<p>129 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = data.drop_duplicates()\ndata[data.duplicated()]","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:26:39.652229Z","iopub.execute_input":"2023-10-24T03:26:39.652602Z","iopub.status.idle":"2023-10-24T03:26:40.361893Z","shell.execute_reply.started":"2023-10-24T03:26:39.652574Z","shell.execute_reply":"2023-10-24T03:26:40.361026Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [Questions, Answers]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Answers</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df, temp_df = train_test_split(data, test_size=0.3, random_state=42)\n\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:51:40.171749Z","iopub.execute_input":"2023-10-24T03:51:40.172170Z","iopub.status.idle":"2023-10-24T03:51:40.219290Z","shell.execute_reply.started":"2023-10-24T03:51:40.172112Z","shell.execute_reply":"2023-10-24T03:51:40.218249Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:51:55.783805Z","iopub.execute_input":"2023-10-24T03:51:55.784677Z","iopub.status.idle":"2023-10-24T03:51:55.929747Z","shell.execute_reply.started":"2023-10-24T03:51:55.784640Z","shell.execute_reply":"2023-10-24T03:51:55.928759Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:51:56.296995Z","iopub.execute_input":"2023-10-24T03:51:56.297855Z","iopub.status.idle":"2023-10-24T03:51:56.303815Z","shell.execute_reply.started":"2023-10-24T03:51:56.297821Z","shell.execute_reply":"2023-10-24T03:51:56.302774Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"},"metadata":{}}]},{"cell_type":"code","source":"sample_encodings = tokenizer(train_df['Questions'][15])","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:52:02.422541Z","iopub.execute_input":"2023-10-24T03:52:02.422918Z","iopub.status.idle":"2023-10-24T03:52:02.432838Z","shell.execute_reply.started":"2023-10-24T03:52:02.422888Z","shell.execute_reply":"2023-10-24T03:52:02.432016Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"sample_encodings.keys()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:52:03.727872Z","iopub.execute_input":"2023-10-24T03:52:03.728594Z","iopub.status.idle":"2023-10-24T03:52:03.734750Z","shell.execute_reply.started":"2023-10-24T03:52:03.728557Z","shell.execute_reply":"2023-10-24T03:52:03.733784Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"code","source":"sample_encodings['input_ids']","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:52:04.647793Z","iopub.execute_input":"2023-10-24T03:52:04.648509Z","iopub.status.idle":"2023-10-24T03:52:04.655449Z","shell.execute_reply.started":"2023-10-24T03:52:04.648477Z","shell.execute_reply":"2023-10-24T03:52:04.654339Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[101,\n 2040,\n 2003,\n 2012,\n 3891,\n 2005,\n 1051,\n 10755,\n 2937,\n 1010,\n 2991,\n 7361,\n 2937,\n 7270,\n 1010,\n 1998,\n 3078,\n 2566,\n 9956,\n 22084,\n 2140,\n 4456,\n 1029,\n 1029,\n 102]"},"metadata":{}}]},{"cell_type":"code","source":"sample_encodings['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:52:07.971080Z","iopub.execute_input":"2023-10-24T03:52:07.971466Z","iopub.status.idle":"2023-10-24T03:52:07.978625Z","shell.execute_reply.started":"2023-10-24T03:52:07.971437Z","shell.execute_reply":"2023-10-24T03:52:07.977529Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"},"metadata":{}}]},{"cell_type":"code","source":"len(sample_encodings['input_ids']), len(sample_encodings['attention_mask'])","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:52:08.870930Z","iopub.execute_input":"2023-10-24T03:52:08.871275Z","iopub.status.idle":"2023-10-24T03:52:08.877364Z","shell.execute_reply.started":"2023-10-24T03:52:08.871246Z","shell.execute_reply":"2023-10-24T03:52:08.876455Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(25, 25)"},"metadata":{}}]},{"cell_type":"code","source":"\" \".join([tokenizer.decode(input_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n         for input_id in sample_encodings['input_ids']])","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:52:09.943569Z","iopub.execute_input":"2023-10-24T03:52:09.944200Z","iopub.status.idle":"2023-10-24T03:52:09.951053Z","shell.execute_reply.started":"2023-10-24T03:52:09.944171Z","shell.execute_reply":"2023-10-24T03:52:09.950154Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"' who is at risk for o ##var ##ian , fall ##op ##ian tube , and primary per ##ito ##nea ##l cancer ? ? '"},"metadata":{}}]},{"cell_type":"code","source":"sample_answer_encodings = tokenizer(train_df['Answers'][15])","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:52:22.466987Z","iopub.execute_input":"2023-10-24T03:52:22.467375Z","iopub.status.idle":"2023-10-24T03:52:22.477682Z","shell.execute_reply.started":"2023-10-24T03:52:22.467345Z","shell.execute_reply":"2023-10-24T03:52:22.476658Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}]},{"cell_type":"code","source":"len(sample_answer_encodings['input_ids']), len(sample_answer_encodings['attention_mask'])","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:52:30.216313Z","iopub.execute_input":"2023-10-24T03:52:30.216948Z","iopub.status.idle":"2023-10-24T03:52:30.223462Z","shell.execute_reply.started":"2023-10-24T03:52:30.216917Z","shell.execute_reply":"2023-10-24T03:52:30.222498Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"(939, 939)"},"metadata":{}}]},{"cell_type":"code","source":"\" \".join([tokenizer.decode(input_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n         for input_id in sample_answer_encodings['input_ids']])","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:52:31.914889Z","iopub.execute_input":"2023-10-24T03:52:31.915713Z","iopub.status.idle":"2023-10-24T03:52:31.942293Z","shell.execute_reply.started":"2023-10-24T03:52:31.915681Z","shell.execute_reply":"2023-10-24T03:52:31.941197Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"' key points - avoiding risk factors and increasing protective factors may help prevent cancer . - the following are risk factors for o ##var ##ian , fall ##op ##ian tube , and primary per ##ito ##nea ##l cancer : - family history of o ##var ##ian , fall ##op ##ian tube , and primary per ##ito ##nea ##l cancer - inherited risk - hormone replacement therapy - weight and height - the following are protective factors for o ##var ##ian , fall ##op ##ian tube , and primary per ##ito ##nea ##l cancer : - oral contra ##ceptive ##s - tuba ##l liga ##tion - breast ##fe ##eding - risk - reducing sal ##ping ##o - o ##op ##hore ##ct ##omy - it is not clear whether the following affect the risk of o ##var ##ian , fall ##op ##ian tube , and primary per ##ito ##nea ##l cancer : - diet - alcohol - as ##pi ##rin and non - ste ##roid ##al anti - inflammatory drugs - smoking - tal ##c - in ##fer ##tility treatment - cancer prevention clinical trials are used to study ways to prevent cancer . - new ways to prevent o ##var ##ian , fall ##op ##ian tube , and primary per ##ito ##nea ##l cancer are being studied in clinical trials . avoiding risk factors and increasing protective factors may help prevent cancer . avoiding cancer risk factors may help prevent certain cancers . risk factors include smoking , being over ##weight , and not getting enough exercise . increasing protective factors such as quit ##ting smoking and exercising may also help prevent some cancers . talk to your doctor or other health care professional about how you might lower your risk of cancer . the following are risk factors for o ##var ##ian , fall ##op ##ian tube , and primary per ##ito ##nea ##l cancer : family history of o ##var ##ian , fall ##op ##ian tube , and primary per ##ito ##nea ##l cancer a woman whose mother or sister had o ##var ##ian cancer has an increased risk of o ##var ##ian cancer . a woman with two or more relatives with o ##var ##ian cancer also has an increased risk of o ##var ##ian cancer . inherited risk the risk of o ##var ##ian cancer is increased in women who have inherited certain changes in the br ##ca ##1 , br ##ca ##2 , or other genes . the risk of o ##var ##ian cancer is also increased in women who have certain inherited syndrome ##s that include : - fa ##mi ##lia ##l site - specific o ##var ##ian cancer syndrome . - fa ##mi ##lia ##l breast / o ##var ##ian cancer syndrome . - hereditary non ##pol ##yp ##osis color ##ect ##al cancer ( h ##np ##cc ; lynch syndrome ) . hormone replacement therapy the use of est ##rogen - only hormone replacement therapy ( hr ##t ) after men ##opa ##use is linked to a slightly increased risk of o ##var ##ian cancer in women who are taking hr ##t or have taken hr ##t within the past 3 years . the risk of o ##var ##ian cancer increases the longer a woman uses est ##rogen - only hr ##t . when hormone therapy is stopped , the risk of o ##var ##ian cancer decreases over time . it is not clear whether there is an increased risk of o ##var ##ian cancer with the use of hr ##t that has both est ##rogen and pro ##ges ##tin . weight and height being over ##weight or obe ##se during the teenage years is linked to an increased risk of o ##var ##ian cancer . being obe ##se is linked to an increased risk of death from o ##var ##ian cancer . being tall ( 5 \\' 8 \" or taller ) may also be linked to a slight increase in the risk of o ##var ##ian cancer . it is not clear whether the following affect the risk of o ##var ##ian , fall ##op ##ian tube , and primary per ##ito ##nea ##l cancer : diet studies of dietary factors including various foods , tea ##s , and nutrients have not found a strong link to o ##var ##ian cancer . alcohol studies have not shown a link between drinking alcohol and the risk of o ##var ##ian cancer . as ##pi ##rin and non - ste ##roid ##al anti - inflammatory drugs some studies of as ##pi ##rin and non - ste ##roid ##al anti - inflammatory drugs ( nsa ##ids ) have found a decreased risk of o ##var ##ian cancer and others have not . smoking some studies found a very small increased risk of one rare type of o ##var ##ian cancer in women who were current smoke ##rs compared with women who never smoked . tal ##c studies of women who used tal ##cum powder ( tal ##c ) dust ##ed on the per ##ine ##um ( the area between the va ##gina and the an ##us ) have not found clear evidence of an increased risk of o ##var ##ian cancer . in ##fer ##tility treatment overall , studies in women using fertility drugs have not found clear evidence of an increased risk of o ##var ##ian cancer . risk of o ##var ##ian border ##line mali ##gnant tumors may be higher in women who take fertility drugs . the risk of invasive o ##var ##ian cancer may be higher in women who do not get pregnant after taking fertility drugs . '"},"metadata":{}}]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:52:39.014340Z","iopub.execute_input":"2023-10-24T03:52:39.014984Z","iopub.status.idle":"2023-10-24T03:52:39.021024Z","shell.execute_reply.started":"2023-10-24T03:52:39.014954Z","shell.execute_reply":"2023-10-24T03:52:39.019967Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(159282, 2)"},"metadata":{}}]},{"cell_type":"code","source":"class QADataset(Dataset):\n  def __init__(\n      self,\n      data,\n      tokenizer,\n      source_max_token_len = 128,\n      target_max_token_len = 32,\n      ):\n    \n    self.data =  data\n    self.tokenizer =  tokenizer\n    self.source_max_token_len =  source_max_token_len\n    self.target_max_token_len =  target_max_token_len\n\n\n  def __len__(self):\n    return len(self.data)\n\n  def __getitem__(self, index: int):\n    data_row = self.data.iloc[index]\n\n    source_encoding = tokenizer(\n      data_row['Questions'],\n      max_length=self.source_max_token_len,\n      padding='max_length',\n      truncation=\"only_second\",\n      return_attention_mask=True,\n      add_special_tokens=True,\n      return_tensors=\"pt\"\n      )\n    \n    target_encoding = tokenizer(\n      data_row['Answers'],\n      max_length=self.target_max_token_len,\n      padding='max_length',\n      truncation=True,\n      return_attention_mask=True,\n      add_special_tokens=True,\n      return_tensors=\"pt\"\n      )\n    \n    labels = target_encoding['input_ids']\n    labels[labels==0] = -100\n\n    return dict(\n        question=data_row['Questions'],\n        answer_text=data_row['Answers'],\n        input_ids=source_encoding[\"input_ids\"].flatten(),\n        attention_mask=source_encoding['attention_mask'].flatten(),\n        labels=labels.flatten()\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:54:32.129281Z","iopub.execute_input":"2023-10-24T03:54:32.129653Z","iopub.status.idle":"2023-10-24T03:54:32.140791Z","shell.execute_reply.started":"2023-10-24T03:54:32.129623Z","shell.execute_reply":"2023-10-24T03:54:32.139585Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class DataModule(pl.LightningDataModule):\n    def __init__(\n          self,\n          train_df,\n          val_df,\n          test_df,\n          tokenizer,\n          batch_size = 8,\n          source_max_token_len = 128,\n          target_max_token_len = 32,\n          ):\n        super().__init__()\n        self.train_df = train_df\n        self.val_df = val_df\n        self.test_df = test_df\n        self.tokenizer = tokenizer\n        self.batch_size = batch_size\n        self.source_max_token_len = source_max_token_len\n        self.target_max_token_len = target_max_token_len\n\n    def setup(self, stage=None):\n        self.train_dataset = QADataset(\n            self.train_df,\n            self.tokenizer,\n            self.source_max_token_len,\n            self.target_max_token_len\n            )\n\n        self.val_dataset = QADataset(\n            self.val_df,\n            self.tokenizer,\n            self.source_max_token_len,\n            self.target_max_token_len\n        )\n        self.test_dataset = QADataset(\n            self.test_df,\n            self.tokenizer,\n            self.source_max_token_len,\n            self.target_max_token_len\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n            num_workers=4\n            )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=self.batch_size,\n            num_workers=4\n            )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=1,\n            num_workers=4\n            )","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:54:32.555892Z","iopub.execute_input":"2023-10-24T03:54:32.556320Z","iopub.status.idle":"2023-10-24T03:54:32.566827Z","shell.execute_reply.started":"2023-10-24T03:54:32.556289Z","shell.execute_reply":"2023-10-24T03:54:32.565766Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 2\nN_EPOCHS = 2\n\ndata_module = DataModule(train_df, val_df, test_df, tokenizer, batch_size=BATCH_SIZE)\ndata_module.setup()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:54:33.016599Z","iopub.execute_input":"2023-10-24T03:54:33.017464Z","iopub.status.idle":"2023-10-24T03:54:33.022413Z","shell.execute_reply.started":"2023-10-24T03:54:33.017430Z","shell.execute_reply":"2023-10-24T03:54:33.021316Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"class QAModel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint, return_dict = True)\n\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        output = self.model(\n            input_ids, \n            attention_mask=attention_mask\n        )\n\n        return output.loss, output\n\n    def training_step(self, batch, batch_idx):\n        input_ids = batch['input_ids']\n        attention_mask=batch['attention_mask']\n        labels = batch['labels']\n        loss, outputs = self(input_ids, attention_mask, labels)\n        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n        return {\"loss\": loss, \"predictions\":outputs, \"labels\": labels}\n\n    def validation_step(self, batch, batch_idx):\n        input_ids = batch['input_ids']\n        attention_mask=batch['attention_mask']\n        labels = batch['labels']\n        loss, outputs = self(input_ids, attention_mask, labels)\n        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        input_ids = batch['input_ids']\n        attention_mask=batch['attention_mask']\n        labels = batch['labels']\n        loss, outputs = self(input_ids, attention_mask, labels)\n        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=0.0001)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:55:14.079555Z","iopub.execute_input":"2023-10-24T03:55:14.080363Z","iopub.status.idle":"2023-10-24T03:55:14.091528Z","shell.execute_reply.started":"2023-10-24T03:55:14.080330Z","shell.execute_reply":"2023-10-24T03:55:14.090488Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"model = QAModel()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:55:14.350611Z","iopub.execute_input":"2023-10-24T03:55:14.351413Z","iopub.status.idle":"2023-10-24T03:55:15.039481Z","shell.execute_reply.started":"2023-10-24T03:55:14.351382Z","shell.execute_reply":"2023-10-24T03:55:15.038536Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint_callback = pl.callbacks.ModelCheckpoint(\n    dirpath=\"/kaggle/working/checkpoints\",\n    filename=\"best-checkpoint\",\n    save_top_k=1,\n    verbose=True,\n    monitor=\"val_loss\",\n    mode=\"min\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:55:15.041378Z","iopub.execute_input":"2023-10-24T03:55:15.042239Z","iopub.status.idle":"2023-10-24T03:55:15.047418Z","shell.execute_reply.started":"2023-10-24T03:55:15.042206Z","shell.execute_reply":"2023-10-24T03:55:15.046462Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(\n    callbacks=checkpoint_callback,\n    max_epochs=N_EPOCHS,\n    accelerator='gpu',\n    devices = 1\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:55:15.048701Z","iopub.execute_input":"2023-10-24T03:55:15.049391Z","iopub.status.idle":"2023-10-24T03:55:15.110459Z","shell.execute_reply.started":"2023-10-24T03:55:15.049356Z","shell.execute_reply":"2023-10-24T03:55:15.109705Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, data_module)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:55:15.406871Z","iopub.execute_input":"2023-10-24T03:55:15.407742Z","iopub.status.idle":"2023-10-24T03:55:16.573264Z","shell.execute_reply.started":"2023-10-24T03:55:15.407710Z","shell.execute_reply":"2023-10-24T03:55:16.571672Z"},"trusted":true},"execution_count":68,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e8f1534ffa48399e81de52f8fdf3ea"}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1021\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1021\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1050\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1047\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m     previous_dataloader_idx \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:376\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[1;32m    375\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 376\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    380\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:294\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 294\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    297\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:393\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[64], line 28\u001b[0m, in \u001b[0;36mQAModel.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(input_ids, attention_mask, labels)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/module.py:406\u001b[0m, in \u001b[0;36mLightningModule.log\u001b[0;34m(self, name, value, prog_bar, logger, on_step, on_epoch, reduce_fx, enable_graph, sync_dist, sync_dist_group, add_dataloader_idx, batch_size, metric_attribute, rank_zero_only)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# check for invalid values\u001b[39;00m\n\u001b[1;32m    405\u001b[0m apply_to_collection(value, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__check_not_nested, name)\n\u001b[0;32m--> 406\u001b[0m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__check_allowed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrong_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnumbers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;66;03m# not an error to support testing the `*_step` methods without a `Trainer` reference\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py:51\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Breaking condition\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype) \u001b[38;5;129;01mand\u001b[39;00m (wrong_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, wrong_dtype)):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m elem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(data)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Recursively apply to collection items\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/module.py:613\u001b[0m, in \u001b[0;36mLightningModule.__check_allowed\u001b[0;34m(v, name, value)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__check_allowed\u001b[39m(v: Any, name: \u001b[38;5;28mstr\u001b[39m, value: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.log(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)` was called, but `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` values cannot be logged\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: `self.log(val_loss, None)` was called, but `NoneType` values cannot be logged"],"ename":"ValueError","evalue":"`self.log(val_loss, None)` was called, but `NoneType` values cannot be logged","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}