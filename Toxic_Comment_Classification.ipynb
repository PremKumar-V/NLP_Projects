{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPdaisQWMkIV0vq7rmuvO1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PremKumar-V/NLP_Projects/blob/main/Toxic_Comment_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_83ihtWfwYrZ"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'"
      ],
      "metadata": {
        "id": "kyU8I71LwwuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "metadata": {
        "id": "2ZDJGO8Nwmdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip jigsaw-toxic-comment-classification-challenge.zip -d data"
      ],
      "metadata": {
        "id": "DRwFjNOpwzt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "YRHor52_w7qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/data/train.csv.zip')\n",
        "test = pd.read_csv('/content/data/test.csv.zip')\n",
        "sub = pd.read_csv('/content/data/sample_submission.csv.zip')"
      ],
      "metadata": {
        "id": "Xe1Asq0Dw-8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(5)"
      ],
      "metadata": {
        "id": "6Qlt3aaUxQpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targetCols = [i for i in train.columns.tolist()][2:]\n",
        "targetCols"
      ],
      "metadata": {
        "id": "YOiv-i8IxUdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for values in targetCols:\n",
        "    print(train[values].value_counts(normalize = True))"
      ],
      "metadata": {
        "id": "hki4XAUJxmqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "metadata": {
        "id": "Cr-kvfdhyRsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1500\n",
        "unk_token = '<unk>'\n",
        "pad_token = '<pad>'"
      ],
      "metadata": {
        "id": "ogs7jZguyzOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "commentsTokens = train['comment_text'].map(tokenizer)"
      ],
      "metadata": {
        "id": "7Yc_131Wyi41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator(commentsTokens, specials = [unk_token, pad_token], max_tokens = VOCAB_SIZE)\n",
        "vocab.set_default_index(vocab[unk_token])"
      ],
      "metadata": {
        "id": "lqU8_0v4y2zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.comment_text.sample(1000).map(tokenizer).map(len).plot(kind='hist');"
      ],
      "metadata": {
        "id": "csphvG0TzMIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 150\n",
        "\n",
        "def padTokens(tokens):\n",
        "    if (len(tokens) >= MAX_LENGTH):\n",
        "        return tokens[:MAX_LENGTH]\n",
        "    else:\n",
        "        return tokens + [pad_token] * (MAX_LENGTH - len(tokens))"
      ],
      "metadata": {
        "id": "c7iw8YJjzWNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, random_split"
      ],
      "metadata": {
        "id": "zC97wpiZzmRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, df, isTest = False):\n",
        "        self.df = df\n",
        "        self.isTest = isTest\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        commentText = self.df['comment_text'].values[index]\n",
        "        commentTokens = padTokens(tokenizer(commentText))\n",
        "        input = torch.tensor(vocab.lookup_indices(commentTokens))\n",
        "\n",
        "        if self.isTest:\n",
        "            target = torch.tensor([0, 0, 0, 0, 0, 0]).float()\n",
        "        else:\n",
        "            target = torch.tensor(self.df[targetCols].values[index]).float()\n",
        "\n",
        "        return input, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "T4-m2AngzqUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rawDataset = ClassificationDataset(train)"
      ],
      "metadata": {
        "id": "mLj4awSo1PKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rawDataset[0]"
      ],
      "metadata": {
        "id": "o7wOg2bc1dhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_FRAC = 0.25"
      ],
      "metadata": {
        "id": "AXycOCyp1edz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataset, valDataset = random_split(rawDataset, [1-VAL_FRAC, VAL_FRAC])"
      ],
      "metadata": {
        "id": "YBd66gnY1heb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDataset = ClassificationDataset(test, isTest = True)\n",
        "\n",
        "testDataset[0]"
      ],
      "metadata": {
        "id": "Zcwc4c3A1nmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "uiIk-FCL2RA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDl = DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=True)\n",
        "valDl = DataLoader(valDataset, batch_size=BATCH_SIZE*2, num_workers=8, pin_memory=True)\n",
        "testDl = DataLoader(testDataset, batch_size=BATCH_SIZE*2, num_workers=8, pin_memory=True)"
      ],
      "metadata": {
        "id": "wSQ1BtUG2ffV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in trainDl:\n",
        "    input, target = batch\n",
        "    print(f\"Inputs Shape: {input.shape}\")\n",
        "    print(f\"Targets Shape: {target.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "A8ZowczT2yTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.functional as f"
      ],
      "metadata": {
        "id": "VYpBupRG2yP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embLayer = nn.Embedding(VOCAB_SIZE, 256, 1)"
      ],
      "metadata": {
        "id": "rhGtRGZ-2yMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnnLayer = nn.RNN(256, 128, 1, batch_first=True)"
      ],
      "metadata": {
        "id": "pyHUUIKDq8B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in trainDl:\n",
        "    input, target = batch\n",
        "    print('Input.shape', input.shape)\n",
        "    print('Target.shape', target.shape)\n",
        "\n",
        "    embOut = embLayer(input)\n",
        "    print('Embedding shape', embOut.shape)\n",
        "\n",
        "    rnnOut, hn = rnnLayer(embOut)\n",
        "    print('RNN shape', rnnOut.shape)\n",
        "    print('Hidden shape', hn.shape)\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "-q404oX2rU4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning --quiet"
      ],
      "metadata": {
        "id": "qbQNezo3rxWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "RB9_d-w6sCbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExtractTensor(nn.Module):\n",
        "    def forward(self,x):\n",
        "        tensor, _ = x\n",
        "        return tensor[:, -1, :]\n"
      ],
      "metadata": {
        "id": "MOAZiUa4wJz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(VOCAB_SIZE, 256, 1)\n",
        "        self.lstm = nn.LSTM(256, 128, 1, batch_first=True)\n",
        "        self.linear = nn.Linear(128, 6)\n",
        "        self.learning_rate = 0.001\n",
        "        self.validation_step_outputs = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.emb(x)\n",
        "        out, hn = self.lstm(out)\n",
        "        out = F.relu(out[:,-1,:])\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, targets = batch\n",
        "        outputs = self(inputs)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        loss = F.binary_cross_entropy(probs, targets)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, targets = batch\n",
        "        outputs = self(inputs)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        loss = F.binary_cross_entropy(probs, targets)\n",
        "        self.validation_step_outputs.append(loss)\n",
        "        return loss.item()\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        loss = torch.stack(self.validation_step_outputs).mean()\n",
        "        print(\"Epoch #{}; Loss: {:4f} \".format(self.current_epoch, loss))\n",
        "        self.validation_step_outputs.clear()\n",
        "\n",
        "#         epoch_average = torch.stack(self.validation_step_outputs).mean()\n",
        "#          self.log(\"validation_epoch_average\", epoch_average)\n",
        "# +        self.validation_step_outputs.clear()  # free memory\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        inputs, targets = batch\n",
        "        outputs = self(inputs)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        return probs\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
      ],
      "metadata": {
        "id": "9jItryPfsLK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ClassificationModel()\n",
        "\n",
        "for batch in trainDl:\n",
        "    input, target = batch\n",
        "    print('Inputs.shape', input.shape)\n",
        "    print('targets.shape', target.shape)\n",
        "\n",
        "    outputs = model(input)\n",
        "    print('outputs shape', outputs.shape)\n",
        "\n",
        "    probs = torch.sigmoid(outputs)\n",
        "    loss = F.binary_cross_entropy(probs, target)\n",
        "    print('Loss', loss)\n",
        "    break"
      ],
      "metadata": {
        "id": "rDzqrO7Ntwbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './model.pth'"
      ],
      "metadata": {
        "id": "DGcxxXxS6WJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(path):\n",
        "    model = torch.load('model.pth')\n",
        "else:\n",
        "    trainer = pl.Trainer(max_epochs=3, accelerator='gpu')\n",
        "    trainer.fit(model, trainDl, valDl)"
      ],
      "metadata": {
        "id": "tHMijXjpt92d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.save(model, 'model.pth')\n",
        "\n",
        "# Load the entire model\n",
        "# model = torch.load('model.pth')\n",
        "# model.eval()  # Put the model in evaluation mode after loading"
      ],
      "metadata": {
        "id": "C_RQ_UNRSOmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-D2wc6NSUW2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}